{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19234b65",
   "metadata": {},
   "source": [
    "### Hello, Data!\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad82e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_18444\\2771697775.py:3: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  df = pd.read_csv(\"D:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\orders.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>coupon_code</th>\n",
       "      <th>shipping_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56:34.9</td>\n",
       "      <td>CUST1000</td>\n",
       "      <td>Headphones</td>\n",
       "      <td>725.04</td>\n",
       "      <td>1</td>\n",
       "      <td>DEAL20</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56:34.9</td>\n",
       "      <td>CUST1001</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>65.62</td>\n",
       "      <td>2</td>\n",
       "      <td>WELCOME</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56:34.9</td>\n",
       "      <td>CUST1002</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>610.04</td>\n",
       "      <td>3</td>\n",
       "      <td>DEAL20</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date customer_id     product   price  quantity coupon_code shipping_city\n",
       "0  56:34.9    CUST1000  Headphones  725.04         1      DEAL20       Houston\n",
       "1  56:34.9    CUST1001    Keyboard   65.62         2     WELCOME       Chicago\n",
       "2  56:34.9    CUST1002    Keyboard  610.04         3      DEAL20   Los Angeles"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"D:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\orders.csv\") \n",
    "df.head(3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11ab4f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'customer_id', 'product', 'price', 'quantity', 'coupon_code',\n",
       "       'shipping_city'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4588b",
   "metadata": {},
   "source": [
    "### Pick the Right Container ###\n",
    "To represent each transaction, we need a structure that:\n",
    "\n",
    "Holds multiple attributes (like date, customer_id, product, etc.)\n",
    "\n",
    "Supports methods for cleaning or calculations (e.g., .clean() or .total())\n",
    "\n",
    "Justification:\n",
    "\n",
    "A Python class is the best fit here because it allows bundling data (attributes) and behavior (methods) together.\n",
    "\n",
    "A dictionary would store data but not behavior.\n",
    "\n",
    "A namedtuple is immutable and doesn't support custom methods easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f9aad",
   "metadata": {},
   "source": [
    "#### Transaction Class and OO data structure\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "196b8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Transaction:\n",
    "    def __init__(self, date: str, customer_id: str, product: str, price: float, quantity: int, coupon_code: Optional[str], shipping_city: str):\n",
    "        self.date = date\n",
    "        self.customer_id = customer_id\n",
    "        self.product = product\n",
    "        self.price = price\n",
    "        self.quantity = quantity\n",
    "        self.coupon_code = coupon_code\n",
    "        self.shipping_city = shipping_city\n",
    "        self.discount_percent = 0.0  # will be set in .clean()\n",
    "\n",
    "    def total(self) -> float:\n",
    "        \"\"\"Calculate total price before discount.\"\"\"\n",
    "        return self.price * self.quantity\n",
    "\n",
    "    def parse_discount(self) -> float:\n",
    "        \"\"\"Extract numeric discount from coupon_code.\"\"\"\n",
    "        if self.coupon_code == \"NONE\":\n",
    "            return 0.0\n",
    "        elif self.coupon_code.startswith(\"DEAL\"):\n",
    "            try:\n",
    "                return float(self.coupon_code.replace(\"DEAL\", \"\"))\n",
    "            except:\n",
    "                return 0.0\n",
    "        elif self.coupon_code == \"WELCOME\":\n",
    "            return 10.0\n",
    "        return 0.0\n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"Standardize and clean data fields.\"\"\"\n",
    "        self.customer_id = self.customer_id.strip().upper()\n",
    "        self.shipping_city = self.shipping_city.strip().title()\n",
    "\n",
    "        # Normalize coupon codes\n",
    "        code = str(self.coupon_code).strip().upper()\n",
    "        if code in {\"\", \"NONE\", \"NULL\", \"NAN\"}:\n",
    "            self.coupon_code = \"NONE\"\n",
    "        else:\n",
    "            self.coupon_code = code\n",
    "\n",
    "        # Parse and store discount\n",
    "        self.discount_percent = self.parse_discount()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec7a30",
   "metadata": {},
   "source": [
    "### Bulk Loader\t\n",
    "load_transactions() returning list ↦ type-hinted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7383d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "# Step 4: Bulk Loader function\n",
    "def load_transactions(df: pd.DataFrame) -> List[Transaction]:\n",
    "    \"\"\"Convert entire DataFrame into a list of Transaction objects.\"\"\"\n",
    "    transactions = []\n",
    "    for _, row in df.iterrows():\n",
    "        transaction = Transaction(\n",
    "            date=row['date'],\n",
    "            customer_id=row['customer_id'],\n",
    "            product=row['product'],\n",
    "            price=row['price'],\n",
    "            quantity=row['quantity'],\n",
    "            coupon_code=row.get('coupon_code'),\n",
    "            shipping_city=row['shipping_city']\n",
    "        )\n",
    "        transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "# Load all transactions\n",
    "all_transactions = load_transactions(df)\n",
    "\n",
    "# Confirm number of transactions loaded\n",
    "len(all_transactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9ae7f",
   "metadata": {},
   "source": [
    "### Quick Profiling\t\n",
    "Min/mean/max price, unique city count (set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52e59a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 20.31, Mean: 742.1563000000001, Max: 1492.66\n",
      "Unique Cities: 5\n"
     ]
    }
   ],
   "source": [
    "prices = [t.price for t in all_transactions]\n",
    "cities = {t.shipping_city for t in all_transactions}\n",
    "\n",
    "min_price = min(prices)\n",
    "mean_price = sum(prices) / len(prices)\n",
    "max_price = max(prices)\n",
    "unique_city_count = len(cities)\n",
    "\n",
    "print(f\"Min: {min_price}, Mean: {mean_price}, Max: {max_price}\")\n",
    "print(f\"Unique Cities: {unique_city_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb09e0",
   "metadata": {},
   "source": [
    "### Spot the Grime\n",
    "\n",
    "Three dirty data examples:\n",
    "\n",
    "1. Inconsistent city names: `\"new york\"`, `\"NEW YORK\"`, and `\"New York\"` should be standardized.\n",
    "2. Some coupon codes are missing, written as `\"none\"` or `\"null\"`.\n",
    "3. The `date` field appears to be improperly formatted (`\"56:34.9\"`) and not usable as a timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3077fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Transaction' object has no attribute 'price'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transactions:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprice\u001b[49m < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m t.quantity <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.shipping_city:\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mvars\u001b[39m(t))\n",
      "\u001b[31mAttributeError\u001b[39m: 'Transaction' object has no attribute 'price'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d806e238",
   "metadata": {},
   "source": [
    "### Cleaning Rules\t\n",
    "Execute fixes inside clean(); show “before/after” counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cc1caf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Cleaning:\n",
      " - Dirty coupons: 0\n",
      " - Unformatted cities: 0\n",
      "\n",
      "After Cleaning:\n",
      " - Standardized 'NONE' coupons: 97\n",
      " - Unique cities: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count before cleaning\n",
    "dirty_coupon_codes = [t.coupon_code for t in all_transactions if not t.coupon_code or str(t.coupon_code).lower() in {\"none\", \"null\", \"\"}]\n",
    "dirty_city_names = [t.shipping_city for t in all_transactions if t.shipping_city != t.shipping_city.title()]\n",
    "\n",
    "print(f\"Before Cleaning:\")\n",
    "print(f\" - Dirty coupons: {len(dirty_coupon_codes)}\")\n",
    "print(f\" - Unformatted cities: {len(dirty_city_names)}\")\n",
    "\n",
    "# Apply cleaning\n",
    "for t in all_transactions:\n",
    "    t.clean()\n",
    "\n",
    "# Count after cleaning\n",
    "dirty_coupon_codes_after = [t.coupon_code for t in all_transactions if t.coupon_code == \"NONE\"]\n",
    "unique_cities_after = {t.shipping_city for t in all_transactions}\n",
    "\n",
    "print(f\"\\nAfter Cleaning:\")\n",
    "print(f\" - Standardized 'NONE' coupons: {len(dirty_coupon_codes_after)}\")\n",
    "print(f\" - Unique cities: {len(unique_cities_after)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf020f",
   "metadata": {},
   "source": [
    "### Transformations\t\n",
    "For example: Parse coupon_code ➞ numeric discount (others apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "13e0cc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coupon: DEAL20, Discount: 20.0%\n",
      "Coupon: WELCOME, Discount: 10.0%\n",
      "Coupon: DEAL20, Discount: 20.0%\n",
      "Coupon: WELCOME, Discount: 10.0%\n",
      "Coupon: FREESHIP, Discount: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Add discount parsing to each transaction\n",
    "for t in all_transactions:\n",
    "    t.clean()  # already includes discount parsing\n",
    "\n",
    "# Show a few examples\n",
    "for t in all_transactions[:5]:\n",
    "    print(f\"Coupon: {t.coupon_code}, Discount: {t.discount_percent}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799831fa",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e1b0bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in transactions:\n",
    "    t.feature_engineer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a771c",
   "metadata": {},
   "source": [
    "# Mini-Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25c40db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "revenue_by_city = defaultdict(float)\n",
    "for t in transactions:\n",
    "    revenue_by_city[t.shipping_city] += t.total()\n",
    "pd.Series(revenue_by_city).sort_values(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c8126",
   "metadata": {},
   "source": [
    "# Serialization Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b121cdd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m clean_data = [{\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m: t.date.isoformat(),\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m\"\u001b[39m: t.customer_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mshipping_city\u001b[39m\u001b[33m\"\u001b[39m: t.shipping_city\n\u001b[32m     11\u001b[39m } \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transactions]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/cleaned_transactions.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecords\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m pd.DataFrame(clean_data).to_parquet(\u001b[33m\"\u001b[39m\u001b[33mdata/cleaned_transactions.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2702\u001b[39m, in \u001b[36mNDFrame.to_json\u001b[39m\u001b[34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[39m\n\u001b[32m   2699\u001b[39m config.is_nonnegative_int(indent)\n\u001b[32m   2700\u001b[39m indent = indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2705\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2717\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\.venv\\Lib\\site-packages\\pandas\\io\\json\\_json.py:217\u001b[39m, in \u001b[36mto_json\u001b[39m\u001b[34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[39m\n\u001b[32m    213\u001b[39m     s = convert_to_line_delimits(s)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path_or_buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    220\u001b[39m         handles.handle.write(s)\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\College Second Program\\PROG8245-Machine Learning Programming\\Lab2\\Lab2_PROG8245\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "clean_data = [{\n",
    "    \"date\": t.date.isoformat(),\n",
    "    \"customer_id\": t.customer_id,\n",
    "    \"product\": t.product,\n",
    "    \"price\": t.price,\n",
    "    \"quantity\": t.quantity,\n",
    "    \"total\": t.total(),\n",
    "    \"discount\": t.discount,\n",
    "    \"days_since_purchase\": t.days_since_purchase,\n",
    "    \"shipping_city\": t.shipping_city\n",
    "} for t in transactions]\n",
    "\n",
    "pd.DataFrame(clean_data).to_json(\"data/cleaned_transactions.json\", orient=\"records\", lines=True)\n",
    "pd.DataFrame(clean_data).to_parquet(\"data/cleaned_transactions.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bcc488",
   "metadata": {},
   "source": [
    "# Soft Interview Reflection\n",
    "\"\"\"\n",
    "### Reflection\n",
    "Using OOP helped encapsulate data cleaning, transformation, and feature engineering logic within the `Transaction` class.\n",
    "This made the overall pipeline modular, reusable, and easier to test or extend. Instead of having fragmented logic,\n",
    "we could centralize business rules directly where they belong.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf75f4",
   "metadata": {},
   "source": [
    "# Data Dictionary Section\n",
    "# Markdown Table\n",
    "\"\"\"\n",
    "### Data Dictionary\n",
    "\n",
    "| Field                | Type     | Description                              | Source        |\n",
    "|----------------------|----------|------------------------------------------|----------------|\n",
    "| date                | datetime | Date of transaction                      | orders_500.csv |\n",
    "| customer_id         | string   | Unique customer identifier               | orders_500.csv |\n",
    "| product             | string   | Name of the product                      | orders_500.csv |\n",
    "| price               | float    | Price per unit                           | orders_500.csv |\n",
    "| quantity            | int      | Number of units purchased                | orders_500.csv |\n",
    "| coupon_code         | string   | Promotional code used                    | orders_500.csv |\n",
    "| shipping_city       | string   | City where order was shipped             | orders_500.csv |\n",
    "| total               | float    | Computed total price = price * quantity  | derived         |\n",
    "| discount            | int      | Numeric discount derived from code       | derived         |\n",
    "| days_since_purchase | int      | Days between purchase and today          | derived         |\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
